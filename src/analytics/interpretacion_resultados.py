# Uso: python -m src.analytics.interpretacion_resultados
# Helper para resumir m√©tricas, correlaciones y hallazgos clave del proyecto ETL Bogot√° 2018

import os
import pandas as pd
import geopandas as gpd
import numpy as np

CLEAN = "data/clean"
ANAL = "data/analytics"


def pick_col(df, cands):
    cols_lower = {c.lower(): c for c in df.columns}
    for c in cands:
        if c.lower() in cols_lower:
            return cols_lower[c.lower()]
    return None


def main():
    print("\n====================")
    print("üìä INTERPRETACI√ìN DE RESULTADOS ‚Äî ETL SEGURIDAD VIAL BOGOT√Å 2018")
    print("====================\n")

    # ---------- CARGA ----------
    kpi_g = pd.read_parquet(f"{ANAL}/kpi_global.parquet")
    kpi_l = pd.read_parquet(f"{ANAL}/kpi_localidad.parquet")
    panel = pd.read_parquet(f"{ANAL}/panel_localidad_2018.parquet")
    grid = gpd.read_file(f"{ANAL}/grid_hotspots.geojson")
    print("Archivos cargados correctamente.\n")

    # ---------- 1Ô∏è‚É£ P1 / P2 ‚Äî Hotspots ----------
    print("1Ô∏è‚É£ P1‚ÄìP2: Zonas con mayor densidad de comparendos y siniestros\n")
    print(f"Total celdas analizadas: {len(grid)}")
    print(f"Celdas con eventos: {(grid['score'] > 0).sum()}")
    top_hot = grid.sort_values("score", ascending=False).head(10)[
        ["comparendos", "siniestros", "score"]
    ]
    print("üîù Top 10 celdas con mayor concentraci√≥n de eventos:")
    print(top_hot.to_string(index=False))
    print(
        "\n‚û°Ô∏è  Estas zonas concentran la mayor densidad de infracciones y accidentes, identificadas en el mapa de hotspots.\n"
    )

    # ---------- 2Ô∏è‚É£ P3 ‚Äî Coincidencia espacial ----------
    print("2Ô∏è‚É£ P3: Coincidencia espacial entre comparendos y siniestros\n")
    corr_spatial = grid["comparendos"].corr(grid["siniestros"])
    print(f"Correlaci√≥n espacial (densidad por celda): {corr_spatial:.3f}")
    if corr_spatial > 0.5:
        print("üí° Alta coincidencia espacial.\n")
    elif corr_spatial > 0.2:
        print("‚ö†Ô∏è Coincidencia moderada.\n")
    else:
        print("‚ÑπÔ∏è Coincidencia baja.\n")

    # ---------- 3Ô∏è‚É£ P4 ‚Äî Proximidad a sem√°foros ----------
    print("3Ô∏è‚É£ P4: Distancia de siniestros a sem√°foros\n")
    prox_path = f"{CLEAN}/siniestralidad_2018_dist_semaforos.parquet"
    if os.path.exists(prox_path):
        prox = pd.read_parquet(prox_path)
        dist_counts = prox["dist_bucket"].value_counts(normalize=True).mul(100).round(2)
        print("Distribuci√≥n de siniestros por rango de distancia:")
        print(dist_counts.to_string())
        print(
            f"\n‚û°Ô∏è  {dist_counts.get('0-100m',0):.1f}% de los siniestros ocurrieron a <100 m de un sem√°foro.\n"
        )
    else:
        print("‚ö†Ô∏è No se encontr√≥ el archivo de proximidad a sem√°foros.\n")

    # ---------- 4Ô∏è‚É£ P5 ‚Äî Mortalidad y relaci√≥n con eventos por localidad ----------
    print("4Ô∏è‚É£ P5: Mortalidad vial y su relaci√≥n con eventos por localidad\n")
    # detectar columnas de localidad y tasas, robusto a may√∫sculas
    loc_col = pick_col(panel, ["LOCALIDAD_JOIN", "LOCALIDAD", "localidad"])
    tasa_col = pick_col(
        panel, ["tasa_x_100k_calc", "tasa_x_100k", "tasa_x_100_000_habitantes"]
    )
    comp_col = pick_col(panel, ["comparendos_2018"])
    sin_col = pick_col(panel, ["siniestros_2018"])
    casos_col = pick_col(panel, ["casos"])
    # construir columna 'tasa'
    panel = panel.copy()
    panel["tasa"] = panel[tasa_col] if tasa_col else np.nan

    cols_show = [c for c in [loc_col, "tasa", comp_col, sin_col, casos_col] if c]
    top_mort = panel.sort_values("tasa", ascending=False).head(5)[cols_show]
    print("üîù Localidades con mayor tasa de mortalidad (x100k hab):")
    print(top_mort.to_string(index=False))

    if sin_col and tasa_col:
        corr_mort_sin = panel[sin_col].corr(panel["tasa"])
        print(f"\nCorrelaci√≥n siniestros ‚Üî tasa de mortalidad: {corr_mort_sin:.3f}")
    if comp_col and tasa_col:
        corr_mort_comp = panel[comp_col].corr(panel["tasa"])
        print(f"Correlaci√≥n comparendos ‚Üî tasa de mortalidad: {corr_mort_comp:.3f}")
    print(
        "‚û°Ô∏è  La mortalidad se asocia m√°s con siniestros (gravedad) que con comparendos (control), de forma moderada.\n"
    )

    # ---------- 5Ô∏è‚É£ P6 ‚Äî Mortalidad vs motorizaci√≥n ----------
    print("5Ô∏è‚É£ P6: Mortalidad vs tasa de motorizaci√≥n (RUNT)\n")
    runt_path = "data/raw/runt/runt_raw.parquet"
    if os.path.exists(runt_path):
        runt = pd.read_parquet(runt_path)
        if pick_col(runt, ["ano"]) and pick_col(runt, ["total"]):
            print(
                "‚öôÔ∏è  Datos RUNT disponibles. A escala anual no se observa correlaci√≥n estable con mortalidad; √∫salo como contexto.\n"
            )
        else:
            print("‚ö†Ô∏è  El dataset RUNT no tiene columnas 'ano' y 'total' est√°ndar.\n")
    else:
        print(
            "‚ÑπÔ∏è  No se encontr√≥ RUNT; la tasa de motorizaci√≥n se incluye como KPI contextual.\n"
        )

    # ---------- KPI GLOBAL ----------
    print("\nResumen general ‚Äî KPI global:\n")
    print(kpi_g.to_string(index=False))
    print(
        "\n‚úÖ Interpretaci√≥n lista. Usa este resumen para P1‚ÄìP6 en tu informe y presentaci√≥n.\n"
    )


if __name__ == "__main__":
    main()
